import os
from dotenv import load_dotenv
import json
from collections import defaultdict
import re

# Load environment variables
load_dotenv()

class AIAnalyzer:
    def __init__(self):
        self.api_key = os.getenv('GROQ_API_KEY')
        self.model_name = os.getenv('GROQ_MODEL', 'llama-3.3-70b-versatile')  # Updated model
        self.client = None  # Initialize to None first
        
        if not self.api_key:
            print("[ERROR] Groq API Key not found in environment variables")
            print("[INFO] Please set GROQ_API_KEY in your .env file")
            # Don't return, allow partial init provided other keys might work later
        
        self.web_api_key = os.getenv('GROQ_API_KEY_WEB')
        self.web_client = None

        try:
            # Import Groq here to give better error message if not installed
            from groq import Groq
            
            # Initialize Standard Client
            if self.api_key:
                self.client = Groq(api_key=self.api_key)
                print(f"[INFO] AI Analyzer (Network) initialized with model: {self.model_name}")

            # Initialize Web Client
            if self.web_api_key:
                self.web_client = Groq(api_key=self.web_api_key)
                print(f"[INFO] AI Analyzer (Web) initialized with separate key.")
            else:
                print(f"[WARNING] GROQ_API_KEY_WEB not set. Web AI features will be disabled.")

        except ImportError:
            print("[ERROR] Groq package not installed")
            print("[INFO] Install it with: pip install groq")
            self.client = None
            self.web_client = None
        except Exception as e:
            print(f"[ERROR] Failed to initialize Groq AI: {e}")
            self.client = None
            self.web_client = None

    def analyze_device(self, device_data):
        """
        Analyze device scan results using Groq AI
        """
        if not self.client:
            return {
                "error": "Groq API client not initialized",
                "summary": "Please check: 1) GROQ_API_KEY is set in .env, 2) groq package is installed (pip install groq)",
                "risk_score": 0,
                "risk_level": "Unknown",
                "vulnerabilities": [],
                "recommendations": ["Install groq package", "Set GROQ_API_KEY in .env file"]
            }

        # Check if we need batch analysis
        if 'ports' in device_data and len(device_data['ports']) > 5:
            print(f"[INFO] Device has {len(device_data['ports'])} ports. Using batch analysis...")
            
            # Sort ports for batch analysis
            priority_services = ['http', 'https', 'ssh', 'ftp', 'telnet', 'smtp', 'mysql', 
                                'postgresql', 'rdp', 'vnc', 'smb', 'nfs', 'rpcbind']
            sorted_ports = sorted(device_data['ports'], 
                                key=lambda p: (p.get('service', '').lower() not in priority_services, 
                                             p.get('port', 99999)))
            
            return self._batch_analysis(device_data, sorted_ports, batch_size=5)
        
        # Normal single analysis
        prompt = self._build_device_analysis_prompt(device_data)
        
        try:
            import time
            start_time = time.time()
            
            # Call Groq API
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "You are a cybersecurity expert analyzing network scan results. Return only valid JSON."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                model=self.model_name,
                temperature=0.5,
                max_tokens=4096,
                top_p=0.9,
            )
            
            elapsed = time.time() - start_time
            print(f"[INFO] AI analysis completed in {elapsed:.2f} seconds")
            
            # Parse JSON from response
            result = self._parse_json_response(chat_completion.choices[0].message.content)
            return result
            
        except Exception as e:
            error_msg = str(e)
            print(f"[ERROR] AI Analysis failed: {error_msg}")
            return {"error": error_msg}

    def _build_device_analysis_prompt(self, device, force_single=False):
        """Build prompt for device analysis"""
        
        # Format ports and services in compact format
        ports_info = []
        if 'ports' in device:
            priority_services = ['http', 'https', 'ssh', 'ftp', 'telnet', 'smtp', 'mysql', 
                                'postgresql', 'rdp', 'vnc', 'smb', 'nfs', 'rpcbind']
            
            sorted_ports = sorted(device['ports'], 
                                key=lambda p: (p.get('service', '').lower() not in priority_services, 
                                             p.get('port', 99999)))
            
            for p in sorted_ports:
                service = p.get('service', 'unknown')
                version = p.get('version', '')
                if version:
                    ports_info.append(f"{p['port']}/{p['protocol']}: {service} {version}")
                else:
                    ports_info.append(f"{p['port']}/{p['protocol']}: {service}")
        
        ports_text = "\n".join(ports_info) if ports_info else "No open ports"
        
        prompt = f"""Analyze {device.get('ip')} for CVEs. Return valid JSON only.

Services:
{ports_text}

Return this exact JSON structure:
{{
  "summary": "Brief 1-2 sentence summary of security posture",
  "risk_score": 9.5,
  "risk_level": "Critical",
  "vulnerabilities": [
    {{
      "title": "CVE-2023-1234 (80)",
      "severity": "High",
      "cvss_score": 7.5,
      "description": "Brief 2-3 sentence description of vulnerability and impact",
      "affected_port": 80
    }}
  ],
  "recommendations": ["Update service to latest version", "Disable if not needed"]
}}

STRICT RULES:
1. Max 4 CVEs per port (newest only)
2. Description: 2-3 sentences (not too long)
3. Recommendations: Short actionable items
4. NO markdown code blocks
5. NO explanations outside JSON
6. Complete ALL fields before stopping
"""
        return prompt
    
    def _batch_analysis(self, device, sorted_ports, batch_size):
        """
        Analyze device in batches when there are too many ports
        Returns combined analysis results
        """
        import math
        import time
        
        num_batches = math.ceil(len(sorted_ports) / batch_size)
        all_vulnerabilities = []
        all_recommendations = set()
        max_risk_score = 0
        summaries = []
        
        print(f"[INFO] Splitting {len(sorted_ports)} ports into {num_batches} batches")
        
        for batch_num in range(num_batches):
            start_idx = batch_num * batch_size
            end_idx = min((batch_num + 1) * batch_size, len(sorted_ports))
            batch_ports = sorted_ports[start_idx:end_idx]
            
            print(f"[INFO] Analyzing batch {batch_num + 1}/{num_batches} ({len(batch_ports)} ports)")
            
            # Create temporary device data for this batch
            batch_device = device.copy()
            batch_device['ports'] = batch_ports
            
            # Build prompt for this batch
            prompt = self._build_device_analysis_prompt(batch_device, force_single=True)
            
            # Analyze this batch
            try:
                # Call Groq API
                chat_completion = self.client.chat.completions.create(
                    messages=[
                        {
                            "role": "system",
                            "content": "You are a cybersecurity expert analyzing network scan results. Return only valid JSON."
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    model=self.model_name,
                    temperature=0.5,
                    max_tokens=4096,
                    top_p=0.9,
                )
                
                response_text = chat_completion.choices[0].message.content
                print(f"[DEBUG] Batch {batch_num + 1} raw response length: {len(response_text)}")
                
                result = self._parse_json_response(response_text)
                
                print(f"[DEBUG] Batch {batch_num + 1} parsed result keys: {result.keys()}")
                
                if 'error' in result:
                    print(f"[WARNING] Batch {batch_num + 1} returned error: {result.get('error')}")
                    continue
                
                if 'vulnerabilities' in result:
                    vuln_count = len(result['vulnerabilities'])
                    all_vulnerabilities.extend(result['vulnerabilities'])
                    print(f"[INFO] Batch {batch_num + 1} found {vuln_count} vulnerabilities")
                
                if 'recommendations' in result:
                    rec_count = len(result['recommendations'])
                    all_recommendations.update(result['recommendations'])
                    print(f"[INFO] Batch {batch_num + 1} has {rec_count} recommendations")
                
                if 'risk_score' in result:
                    batch_risk = float(result.get('risk_score', 0))
                    max_risk_score = max(max_risk_score, batch_risk)
                    print(f"[INFO] Batch {batch_num + 1} risk score: {batch_risk}")
                
                if 'summary' in result:
                    summaries.append(result['summary'])
                
                # Small delay between batches (Groq allows 30/min, so ~2s is safe)
                if batch_num < num_batches - 1:
                    time.sleep(2)
                    
            except Exception as e:
                print(f"[ERROR] Batch {batch_num + 1} analysis failed: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        print(f"[INFO] Batch analysis complete. Total vulnerabilities: {len(all_vulnerabilities)}, Total recommendations: {len(all_recommendations)}")
        
        # Filter vulnerabilities: max 4 per port, prioritize newest CVEs
        filtered_vulns = self._filter_vulnerabilities_by_port(all_vulnerabilities)
        print(f"[INFO] After filtering (max 4 per port): {len(filtered_vulns)} vulnerabilities")
        
        # Combine results
        combined_summary = f"Analysis of {len(sorted_ports)} ports across {num_batches} batches. " + " ".join(summaries[:2])
        
        # Determine risk level
        if max_risk_score >= 9.0:
            risk_level = "Critical"
        elif max_risk_score >= 7.0:
            risk_level = "High"
        elif max_risk_score >= 4.0:
            risk_level = "Medium"
        else:
            risk_level = "Low"
        
        return {
            "summary": combined_summary,
            "risk_score": max_risk_score,
            "risk_level": risk_level,
            "vulnerabilities": filtered_vulns,
            "recommendations": list(all_recommendations)
        }
    
    def _filter_vulnerabilities_by_port(self, vulnerabilities):
        """
        Filter vulnerabilities to max 4 per port, prioritizing newest CVEs
        """
        port_vulns = defaultdict(list)
        for vuln in vulnerabilities:
            port = vuln.get('affected_port', 'unknown')
            port_vulns[port].append(vuln)
        
        filtered = []
        for port, vulns in port_vulns.items():
            def get_cve_year(vuln):
                title = vuln.get('title', '')
                match = re.search(r'CVE-(\d{4})', title)
                if match:
                    return int(match.group(1))
                return 0
            
            sorted_vulns = sorted(vulns, key=get_cve_year, reverse=True)
            filtered.extend(sorted_vulns[:4])
        
        return filtered

    def _parse_json_response(self, text):
        """Clean and parse JSON response"""
        try:
            # Remove markdown formatting if present
            clean_text = text.replace('```json', '').replace('```', '').strip()
            
            # Try to parse JSON
            parsed = json.loads(clean_text)
            
            # Validate required keys
            if 'summary' not in parsed or 'risk_score' not in parsed:
                print(f"[WARNING] AI response missing required keys. Keys found: {parsed.keys()}")
            
            return parsed
            
        except json.JSONDecodeError as e:
            print(f"[ERROR] Failed to parse JSON response: {e}")
            print(f"[DEBUG] Raw response (first 500 chars): {text[:500]}")
            
            return {
                "error": "Could not parse AI response as JSON",
                "summary": "AI returned invalid JSON format",
                "risk_score": 0,
                "risk_level": "Unknown",
                "vulnerabilities": [],
                "recommendations": [],
                "raw_response": text[:1000]
            }

    def parse_web_scan_results(self, nikto_output: str, gobuster_output: str) -> dict:
        """
        Parse raw Nikto and Gobuster logs into structured JSON for AI analysis.
        
        Args:
            nikto_output (str): Raw Nikto scan output
            gobuster_output (str): Raw Gobuster scan output (or list of strings)
            
        Returns:
            dict: Structured data with general findings and path-based findings
        """
        import re
        results = {
            "master_summary": "", # AI to fill
            "general": {"findings": [], "avg_risk": 0.0},
            "paths": {}
        }
        
        # --- Helper for Finding Type ---
        def determine_type(path):
            if path.endswith('/'): return "Directory"
            if any(ext in path for ext in ['.bak', '.old', '.backup', '.swp', '.zip', '.tar']): return "Backup"
            if any(ext in path for ext in ['.conf', '.config', '.ini', '.xml']): return "Config"
            if any(ext in path for ext in ['.sql', '.db']): return "Database"
            if '.' in path.split('/')[-1]: return "File"
            return "Directory"

        # --- Parse Gobuster (Define Paths) ---
        if gobuster_output:
            # Handle if input is list
            if isinstance(gobuster_output, list):
                gobuster_lines = gobuster_output
            else:
                gobuster_lines = gobuster_output.splitlines()

            # Pattern: /admin (Status: 301) [Size: 123]
            gobuster_pattern = re.compile(r"^\s*(\/\S+)\s+\(Status:\s*(\d+)\)")
            
            for line in gobuster_lines:
                match = gobuster_pattern.search(line)
                if match:
                    path = match.group(1)
                    status_code = int(match.group(2))
                    
                    results["paths"][path] = {
                        "status": status_code,
                        "type": determine_type(path),
                        "vulnerabilities": [],
                        "remaining_count": 0,
                        "avg_risk": 0.0
                    }

        # --- Parse Nikto (Populate Vulnerabilities) ---
        if nikto_output:
            if isinstance(nikto_output, list):
                nikto_lines = nikto_output
            else:
                nikto_lines = nikto_output.splitlines()
                
            # Regex for Nikto lines: "+ /path/ : Potential vulnerability..." or "+ Target IP: General issue"
            # We look for lines starting with "+ "
            
            for line in nikto_lines:
                if not line.startswith("+ "):
                    continue
                    
                content = line[2:].strip()
                
                # Try to extract path: "+ /admin/config.php : Description"
                # Pattern: Starts with /... : 
                path_match = re.match(r"^(\/[^\s:]+)\s*:", content)
                
                target_path = None
                description = content
                
                if path_match:
                    match_path = path_match.group(1)
                    # Normalize path (remove trailing colon if captured)
                    match_path = match_path.strip()
                    
                    # Check if this path exists in our Gobuster results or is a sub-path
                    # For simplicty, exact match or if it looks like a path
                    target_path = match_path
                    
                    # Clean description
                    description = content[len(match_path):].strip(": ").strip()
                
                vuln_obj = {
                    "name": description[:50] + "..." if len(description) > 50 else description, # Short name
                    "risk": 0.0, # Initial 0 per requirement
                    "desc": description
                }
                
                if target_path:
                    # Ensure path exists in results or add it
                    if target_path not in results["paths"]:
                        results["paths"][target_path] = {
                            "status": 0, # Unknown status
                            "type": determine_type(target_path),
                            "vulnerabilities": [],
                            "remaining_count": 0,
                            "avg_risk": 0.0
                        }
                    
                    # Add to path
                    path_entry = results["paths"][target_path]
                    if len(path_entry["vulnerabilities"]) < 5:
                        path_entry["vulnerabilities"].append(vuln_obj)
                    else:
                        path_entry["remaining_count"] += 1
                else:
                    # General / Server-wide
                    # You might want to filter generic headers here
                    if "Server:" not in description and "No CGI Directories" not in description:
                        # Add to general
                         if len(results["general"]["findings"]) < 20: # Cap general too just in case
                            results["general"]["findings"].append(vuln_obj)

        return results

    def analyze_web_scan(self, parsed_results: dict) -> dict:
        """
        Analyze parsed web scan results using Groq AI (Web Key) to generate Master Path.
        """
        if not self.web_client:
            return {
                "error": "Groq Web Client not initialized. Check GROQ_API_KEY_WEB.",
                "master_summary": "AI Analizi yapılamadı (API Key eksik).",
                "general": parsed_results.get("general", {}),
                "paths": parsed_results.get("paths", {})
            }

        # Build Prompt
        prompt = self._build_web_analysis_prompt(parsed_results)
        
        try:
            chat_completion = self.web_client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "You are an elite penetration tester. Analyze web scan data to find the 'Master Path' - the most critical attack vector. Return ONLY valid JSON."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                model=self.model_name,
                temperature=0.3, # Lower temperature for more structured/deterministic output
                max_tokens=4096,
                top_p=0.9,
            )
            
            # Parse AI Response
            response_text = chat_completion.choices[0].message.content
            ai_data = self._parse_json_response(response_text)
            
            # Merge AI data with parsed results
            # We expect AI to return:
            # {
            #   "master_path_target": "/admin", (Which path is the master path)
            #   "master_summary": "...",
            #   "attack_steps": ["Step 1...", "Step 2..."],
            #   "recommendations": ["Rec 1...", "Rec 2..."],
            #   "path_risks": { "/admin": 9.5, "/config.php": 8.0 } (AI estimated risks)
            # }
            
            # Update Risks in parsed_results
            if "path_risks" in ai_data:
                for path, risk in ai_data["path_risks"].items():
                    if path in parsed_results["paths"]:
                        parsed_results["paths"][path]["avg_risk"] = risk
                        # Also update general button risk if needed, or UI handles it?
            
            # Add Master Path Info to the specific path
            master_target = ai_data.get("master_path_target")
            if master_target and master_target in parsed_results["paths"]:
                parsed_results["paths"][master_target]["is_master"] = True
                parsed_results["paths"][master_target]["attack_steps"] = ai_data.get("attack_steps", [])
            
            # Add Recommendations to General or specific?
            # The UI has a global "Recommendations" panel.
            parsed_results["global_recommendations"] = ai_data.get("recommendations", [])
            parsed_results["master_summary"] = ai_data.get("master_summary", "")
            
            return parsed_results
            
        except Exception as e:
            print(f"[ERROR] Web AI Analysis failed: {e}")
            return parsed_results

    def _build_web_analysis_prompt(self, results):
        """Construct the prompt for Web Scan Analysis"""
        
        # Summarize Paths for Token Efficiency
        paths_summary = []
        for path, data in results.get("paths", {}).items():
            vuln_count = len(data.get("vulnerabilities", []))
            top_vulns = [v['name'] for v in data.get("vulnerabilities", [])[:3]]
            paths_summary.append(f"""
- Path: {path} (Status: {data['status']}, Type: {data['type']})
  Vulns: {vuln_count} found. Top: {', '.join(top_vulns)}
""")
        
        paths_text = "\n".join(paths_summary)
        
        prompt = f"""
Analyze these Web Scan results (Gobuster + Nikto).
Identify the SINGLE most critical "HEAD" or "MASTER PATH" that an attacker would prioritize.

Input Data:
{paths_text}

General Findings:
{len(results.get('general', {}).get('findings', []))} general issues found.

Task:
1. Select the "Master Path" (The one with highest RCE/Shell/Admin potential).
2. Assign a Risk Score (0-10) to EACH path based on its criticalness.
3. Create a step-by-step "Attack Path" for the Master Path.
4. Provide Remediation steps.

Return JSON:
{{
  "master_path_target": "/selected_path",
  "master_summary": "Short explanation why this is the master path",
  "path_risks": {{ "/path1": 8.5, "/path2": 5.0, ... }},
  "attack_steps": [
    "1. Exploit X vulnerability at /path...",
    "2. Brute force login...",
    "3. Achieve RCE..."
  ],
  "recommendations": [
    "Fix 1...",
    "Fix 2..."
  ]
}}
"""
        return prompt
if __name__ == '__main__':
    analyzer = AIAnalyzer()
    test_device = {
        'ip': '192.168.1.1',
        'ports': [
            {'port': 80, 'protocol': 'tcp', 'service': 'http', 'version': 'Apache 2.4.41'},
            {'port': 22, 'protocol': 'tcp', 'service': 'ssh', 'version': 'OpenSSH 7.2'}
        ]
    }
    # print(analyzer.analyze_device(test_device))
