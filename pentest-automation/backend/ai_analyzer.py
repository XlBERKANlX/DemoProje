import os

# Fix for "C-ares status is not ARES_SUCCESS" error on Linux/Kali
# Must be set BEFORE importing google.generativeai
os.environ['GRPC_DNS_RESOLVER'] = 'native'

import google.generativeai as genai
import json
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class AIAnalyzer:
    def __init__(self):
        self.api_key = os.getenv('GEMINI_API_KEY')
        self.model_name = os.getenv('GEMINI_MODEL', 'gemini-2.5-flash')
        
        if not self.api_key:
            print("[ERROR] Gemini API Key not found in environment variables")
            return
            
        try:
            genai.configure(api_key=self.api_key)
            
            # Configure generation settings with increased timeout
            generation_config = {
                "temperature": 0.7,
                "top_p": 0.95,
                "top_k": 40,
                "max_output_tokens": 8192,  # Increased from 2048 to prevent truncation
            }
            
            # Configure safety settings
            safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
            
            self.model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config=generation_config,
                safety_settings=safety_settings
            )
            print(f"[INFO] AI Analyzer initialized with model: {self.model_name}")
        except Exception as e:
            print(f"[ERROR] Failed to initialize Gemini AI: {e}")

    def analyze_device(self, device_data):
        """
        Analyze device scan results using Gemini AI
        """
        if not self.api_key:
            return {"error": "API Key not configured"}

        # Check if we need batch analysis
        if 'ports' in device_data and len(device_data['ports']) > 20:
            print(f"[INFO] Device has {len(device_data['ports'])} ports. Using batch analysis...")
            
            # Sort ports for batch analysis
            priority_services = ['http', 'https', 'ssh', 'ftp', 'telnet', 'smtp', 'mysql', 
                                'postgresql', 'rdp', 'vnc', 'smb', 'nfs', 'rpcbind']
            sorted_ports = sorted(device_data['ports'], 
                                key=lambda p: (p.get('service', '').lower() not in priority_services, 
                                             p.get('port', 99999)))
            
            return self._batch_analysis(device_data, sorted_ports, batch_size=20)
        
        # Normal single analysis
        prompt = self._build_device_analysis_prompt(device_data)
        
        try:
            # Generate response with timeout handling
            import time
            start_time = time.time()
            
            # Generate content (timeout is handled by generation_config)
            response = self.model.generate_content(prompt)
            
            elapsed = time.time() - start_time
            print(f"[INFO] AI analysis completed in {elapsed:.2f} seconds")
            
            # Parse JSON from response
            result = self._parse_json_response(response.text)
            return result
            
        except Exception as e:
            error_msg = str(e)
            print(f"[ERROR] AI Analysis failed: {error_msg}")
            
            # Check for timeout errors
            if "timeout" in error_msg.lower() or "504" in error_msg:
                return {
                    "error": "Request timeout: Analysis took too long. Try scanning fewer ports or a simpler target.",
                    "details": error_msg
                }
            
            # Check for common DNS/Network errors
            if "503" in error_msg or "DNS" in error_msg or "C-ares" in error_msg:
                 return {
                     "error": "Network/DNS Error: Could not reach Gemini API. Please check internet connection.",
                     "details": error_msg
                 }
            
            return {"error": error_msg}

    def _build_device_analysis_prompt(self, device, force_single=False):
        """Build prompt for device analysis"""
        
        # Format ports and services in compact format
        ports_info = []
        if 'ports' in device:
            # Prioritize well-known vulnerable services for ordering
            priority_services = ['http', 'https', 'ssh', 'ftp', 'telnet', 'smtp', 'mysql', 
                                'postgresql', 'rdp', 'vnc', 'smb', 'nfs', 'rpcbind']
            
            # Sort ports: priority services first, then by port number
            sorted_ports = sorted(device['ports'], 
                                key=lambda p: (p.get('service', '').lower() not in priority_services, 
                                             p.get('port', 99999)))
            
            # Format all ports in compact format
            for p in sorted_ports:
                service = p.get('service', 'unknown')
                version = p.get('version', '')
                if version:
                    ports_info.append(f"{p['port']}/{p['protocol']}: {service} {version}")
                else:
                    ports_info.append(f"{p['port']}/{p['protocol']}: {service}")
        
        ports_text = "\n".join(ports_info) if ports_info else "No open ports"
        
        prompt = f"""Analyze network scan for security vulnerabilities.

Target: {device.get('ip')} ({device.get('hostname', 'N/A')})
OS: {device.get('os', 'Unknown')}

Services:
{ports_text}

Return JSON:
{{
  "summary": "Security summary",
  "risk_score": 0-10,
  "risk_level": "Low/Medium/High/Critical",
  "vulnerabilities": [
    {{
      "title": "CVE-XXXX-XXXX or issue",
      "severity": "Low/Medium/High/Critical",
      "cvss_score": 0-10,
      "description": "Brief description",
      "affected_port": port_number
    }}
  ],
  "recommendations": ["Action 1", "Action 2"]
}}

Focus on known CVEs with CVSS v3.1 scores. Return ONLY valid JSON.
"""
        return prompt
    
    def _batch_analysis(self, device, sorted_ports, batch_size):
        """
        Analyze device in batches when there are too many ports
        Returns combined analysis results
        """
        import math
        
        num_batches = math.ceil(len(sorted_ports) / batch_size)
        all_vulnerabilities = []
        all_recommendations = set()
        max_risk_score = 0
        summaries = []
        
        print(f"[INFO] Splitting {len(sorted_ports)} ports into {num_batches} batches")
        
        for batch_num in range(num_batches):
            start_idx = batch_num * batch_size
            end_idx = min((batch_num + 1) * batch_size, len(sorted_ports))
            batch_ports = sorted_ports[start_idx:end_idx]
            
            print(f"[INFO] Analyzing batch {batch_num + 1}/{num_batches} ({len(batch_ports)} ports)")
            
            # Create temporary device data for this batch
            batch_device = device.copy()
            batch_device['ports'] = batch_ports
            
            # Build prompt for this batch (force single analysis, no recursion)
            prompt = self._build_device_analysis_prompt(batch_device, force_single=True)
            
            # Analyze this batch
            try:
                import time
                # Generate content (timeout is handled by generation_config)
                response = self.model.generate_content(prompt)
                
                print(f"[DEBUG] Batch {batch_num + 1} raw response length: {len(response.text)}")
                
                result = self._parse_json_response(response.text)
                
                print(f"[DEBUG] Batch {batch_num + 1} parsed result keys: {result.keys()}")
                
                if 'error' in result:
                    print(f"[WARNING] Batch {batch_num + 1} returned error: {result.get('error')}")
                    continue
                
                if 'vulnerabilities' in result:
                    vuln_count = len(result['vulnerabilities'])
                    all_vulnerabilities.extend(result['vulnerabilities'])
                    print(f"[INFO] Batch {batch_num + 1} found {vuln_count} vulnerabilities")
                
                if 'recommendations' in result:
                    rec_count = len(result['recommendations'])
                    all_recommendations.update(result['recommendations'])
                    print(f"[INFO] Batch {batch_num + 1} has {rec_count} recommendations")
                
                if 'risk_score' in result:
                    batch_risk = float(result.get('risk_score', 0))
                    max_risk_score = max(max_risk_score, batch_risk)
                    print(f"[INFO] Batch {batch_num + 1} risk score: {batch_risk}")
                
                if 'summary' in result:
                    summaries.append(result['summary'])
                
                # Small delay between batches to avoid rate limiting
                if batch_num < num_batches - 1:
                    time.sleep(1)
                    
            except Exception as e:
                print(f"[ERROR] Batch {batch_num + 1} analysis failed: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        print(f"[INFO] Batch analysis complete. Total vulnerabilities: {len(all_vulnerabilities)}, Total recommendations: {len(all_recommendations)}")
        
        # Combine results
        combined_summary = f"Analysis of {len(sorted_ports)} ports across {num_batches} batches. " + " ".join(summaries[:2])
        
        # Determine risk level
        if max_risk_score >= 9.0:
            risk_level = "Critical"
        elif max_risk_score >= 7.0:
            risk_level = "High"
        elif max_risk_score >= 4.0:
            risk_level = "Medium"
        else:
            risk_level = "Low"
        
        return {
            "summary": combined_summary,
            "risk_score": max_risk_score,
            "risk_level": risk_level,
            "vulnerabilities": all_vulnerabilities,
            "recommendations": list(all_recommendations)
        }

    def _parse_json_response(self, text):
        """Clean and parse JSON response"""
        try:
            # Remove markdown formatting if present
            clean_text = text.replace('```json', '').replace('```', '').strip()
            
            # Check if response looks truncated
            if not clean_text.endswith('}'):
                print(f"[WARNING] Response appears truncated (doesn't end with }})")
                print(f"[DEBUG] Last 100 chars: ...{clean_text[-100:]}")
                # Try to find the last complete JSON object
                # Look for the last occurrence of }}
                last_brace = clean_text.rfind('}')
                if last_brace > 0:
                    clean_text = clean_text[:last_brace + 1]
                    print(f"[INFO] Attempting to parse truncated JSON up to last brace")
            
            # Try to parse JSON
            parsed = json.loads(clean_text)
            
            # Validate required keys
            if 'summary' not in parsed or 'risk_score' not in parsed:
                print(f"[WARNING] AI response missing required keys. Keys found: {parsed.keys()}")
            
            return parsed
            
        except json.JSONDecodeError as e:
            # Log the parsing error
            print(f"[ERROR] Failed to parse JSON response: {e}")
            print(f"[DEBUG] Raw response (first 500 chars): {text[:500]}")
            print(f"[DEBUG] Raw response (last 200 chars): ...{text[-200:]}")
            
            # Return error response
            return {
                "error": "Could not parse AI response as JSON",
                "summary": "AI returned invalid JSON format (possibly truncated)",
                "risk_score": 0,
                "risk_level": "Unknown",
                "vulnerabilities": [],
                "recommendations": [],
                "raw_response": text[:1000]  # Limit raw response size
            }

if __name__ == '__main__':
    # Test
    analyzer = AIAnalyzer()
    test_device = {
        'ip': '192.168.1.1',
        'ports': [
            {'port': 80, 'protocol': 'tcp', 'service': 'http', 'version': 'Apache 2.4.41'},
            {'port': 22, 'protocol': 'tcp', 'service': 'ssh', 'version': 'OpenSSH 7.2'}
        ]
    }
    print(analyzer.analyze_device(test_device))
