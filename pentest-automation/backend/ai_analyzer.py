import os
from dotenv import load_dotenv
import json
from collections import defaultdict
import re

# Load environment variables
load_dotenv()

class AIAnalyzer:
    def __init__(self):
        self.api_key = os.getenv('GROQ_API_KEY')
        self.model_name = os.getenv('GROQ_MODEL', 'llama-3.3-70b-versatile')  # Updated model
        self.client = None  # Initialize to None first
        
        if not self.api_key:
            print("[ERROR] Groq API Key not found in environment variables")
            print("[INFO] Please set GROQ_API_KEY in your .env file")
            # Don't return, allow partial init provided other keys might work later
        
        self.web_api_key = os.getenv('GROQ_API_KEY_WEB')
        self.web_client = None

        try:
            # Import Groq here to give better error message if not installed
            from groq import Groq
            
            # Initialize Standard Client
            if self.api_key:
                self.client = Groq(api_key=self.api_key)
                print(f"[INFO] AI Analyzer (Network) initialized with model: {self.model_name}")

            # Initialize Web Client
            if self.web_api_key:
                self.web_client = Groq(api_key=self.web_api_key)
                print(f"[INFO] AI Analyzer (Web) initialized with separate key.")
            else:
                print(f"[WARNING] GROQ_API_KEY_WEB not set. Web AI features will be disabled.")

        except ImportError:
            print("[ERROR] Groq package not installed")
            print("[INFO] Install it with: pip install groq")
            self.client = None
            self.web_client = None
        except Exception as e:
            print(f"[ERROR] Failed to initialize Groq AI: {e}")
            self.client = None
            self.web_client = None

    def analyze_device(self, device_data):
        """
        Analyze device scan results using Groq AI
        """
        if not self.client:
            return {
                "error": "Groq API client not initialized",
                "summary": "Please check: 1) GROQ_API_KEY is set in .env, 2) groq package is installed (pip install groq)",
                "risk_score": 0,
                "risk_level": "Unknown",
                "vulnerabilities": [],
                "recommendations": ["Install groq package", "Set GROQ_API_KEY in .env file"]
            }

        # Check if we need batch analysis
        if 'ports' in device_data and len(device_data['ports']) > 5:
            print(f"[INFO] Device has {len(device_data['ports'])} ports. Using batch analysis...")
            
            # Sort ports for batch analysis
            priority_services = ['http', 'https', 'ssh', 'ftp', 'telnet', 'smtp', 'mysql', 
                                'postgresql', 'rdp', 'vnc', 'smb', 'nfs', 'rpcbind']
            sorted_ports = sorted(device_data['ports'], 
                                key=lambda p: (p.get('service', '').lower() not in priority_services, 
                                             p.get('port', 99999)))
            
            return self._batch_analysis(device_data, sorted_ports, batch_size=5)
        
        # Normal single analysis
        prompt = self._build_device_analysis_prompt(device_data)
        
        try:
            import time
            start_time = time.time()
            
            # Call Groq API
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "You are a cybersecurity expert analyzing network scan results. Return only valid JSON."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                model=self.model_name,
                temperature=0.5,
                max_tokens=4096,
                top_p=0.9,
            )
            
            elapsed = time.time() - start_time
            print(f"[INFO] AI analysis completed in {elapsed:.2f} seconds")
            
            # Parse JSON from response
            result = self._parse_json_response(chat_completion.choices[0].message.content)
            return result
            
        except Exception as e:
            error_msg = str(e)
            print(f"[ERROR] AI Analysis failed: {error_msg}")
            return {"error": error_msg}

    def _build_device_analysis_prompt(self, device, force_single=False):
        """Build prompt for device analysis"""
        
        # Format ports and services in compact format
        ports_info = []
        if 'ports' in device:
            priority_services = ['http', 'https', 'ssh', 'ftp', 'telnet', 'smtp', 'mysql', 
                                'postgresql', 'rdp', 'vnc', 'smb', 'nfs', 'rpcbind']
            
            sorted_ports = sorted(device['ports'], 
                                key=lambda p: (p.get('service', '').lower() not in priority_services, 
                                             p.get('port', 99999)))
            
            for p in sorted_ports:
                service = p.get('service', 'unknown')
                version = p.get('version', '')
                if version:
                    ports_info.append(f"{p['port']}/{p['protocol']}: {service} {version}")
                else:
                    ports_info.append(f"{p['port']}/{p['protocol']}: {service}")
        
        ports_text = "\n".join(ports_info) if ports_info else "No open ports"
        
        prompt = f"""Analyze {device.get('ip')} for CVEs. Return valid JSON only.

Services:
{ports_text}

Return this exact JSON structure:
{{
  "summary": "Brief 1-2 sentence summary of security posture",
  "risk_score": 9.5,
  "risk_level": "Critical",
  "vulnerabilities": [
    {{
      "title": "CVE-2023-1234 (80)",
      "severity": "High",
      "cvss_score": 7.5,
      "description": "Brief 2-3 sentence description of vulnerability and impact",
      "affected_port": 80
    }}
  ],
  "recommendations": ["Update service to latest version", "Disable if not needed"]
}}

STRICT RULES:
1. Max 4 CVEs per port (newest only)
2. Description: 2-3 sentences (not too long)
3. Recommendations: Short actionable items
4. NO markdown code blocks
5. NO explanations outside JSON
6. Complete ALL fields before stopping
"""
        return prompt
    
    def _batch_analysis(self, device, sorted_ports, batch_size):
        """
        Analyze device in batches when there are too many ports
        Returns combined analysis results
        """
        import math
        import time
        
        num_batches = math.ceil(len(sorted_ports) / batch_size)
        all_vulnerabilities = []
        all_recommendations = set()
        max_risk_score = 0
        summaries = []
        
        print(f"[INFO] Splitting {len(sorted_ports)} ports into {num_batches} batches")
        
        for batch_num in range(num_batches):
            start_idx = batch_num * batch_size
            end_idx = min((batch_num + 1) * batch_size, len(sorted_ports))
            batch_ports = sorted_ports[start_idx:end_idx]
            
            print(f"[INFO] Analyzing batch {batch_num + 1}/{num_batches} ({len(batch_ports)} ports)")
            
            # Create temporary device data for this batch
            batch_device = device.copy()
            batch_device['ports'] = batch_ports
            
            # Build prompt for this batch
            prompt = self._build_device_analysis_prompt(batch_device, force_single=True)
            
            # Analyze this batch
            try:
                # Call Groq API
                chat_completion = self.client.chat.completions.create(
                    messages=[
                        {
                            "role": "system",
                            "content": "You are a cybersecurity expert analyzing network scan results. Return only valid JSON."
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    model=self.model_name,
                    temperature=0.5,
                    max_tokens=4096,
                    top_p=0.9,
                )
                
                response_text = chat_completion.choices[0].message.content
                print(f"[DEBUG] Batch {batch_num + 1} raw response length: {len(response_text)}")
                
                result = self._parse_json_response(response_text)
                
                print(f"[DEBUG] Batch {batch_num + 1} parsed result keys: {result.keys()}")
                
                if 'error' in result:
                    print(f"[WARNING] Batch {batch_num + 1} returned error: {result.get('error')}")
                    continue
                
                if 'vulnerabilities' in result:
                    vuln_count = len(result['vulnerabilities'])
                    all_vulnerabilities.extend(result['vulnerabilities'])
                    print(f"[INFO] Batch {batch_num + 1} found {vuln_count} vulnerabilities")
                
                if 'recommendations' in result:
                    rec_count = len(result['recommendations'])
                    all_recommendations.update(result['recommendations'])
                    print(f"[INFO] Batch {batch_num + 1} has {rec_count} recommendations")
                
                if 'risk_score' in result:
                    batch_risk = float(result.get('risk_score', 0))
                    max_risk_score = max(max_risk_score, batch_risk)
                    print(f"[INFO] Batch {batch_num + 1} risk score: {batch_risk}")
                
                if 'summary' in result:
                    summaries.append(result['summary'])
                
                # Small delay between batches (Groq allows 30/min, so ~2s is safe)
                if batch_num < num_batches - 1:
                    time.sleep(2)
                    
            except Exception as e:
                print(f"[ERROR] Batch {batch_num + 1} analysis failed: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        print(f"[INFO] Batch analysis complete. Total vulnerabilities: {len(all_vulnerabilities)}, Total recommendations: {len(all_recommendations)}")
        
        # Filter vulnerabilities: max 4 per port, prioritize newest CVEs
        filtered_vulns = self._filter_vulnerabilities_by_port(all_vulnerabilities)
        print(f"[INFO] After filtering (max 4 per port): {len(filtered_vulns)} vulnerabilities")
        
        # Combine results
        combined_summary = f"Analysis of {len(sorted_ports)} ports across {num_batches} batches. " + " ".join(summaries[:2])
        
        # Determine risk level
        if max_risk_score >= 9.0:
            risk_level = "Critical"
        elif max_risk_score >= 7.0:
            risk_level = "High"
        elif max_risk_score >= 4.0:
            risk_level = "Medium"
        else:
            risk_level = "Low"
        
        return {
            "summary": combined_summary,
            "risk_score": max_risk_score,
            "risk_level": risk_level,
            "vulnerabilities": filtered_vulns,
            "recommendations": list(all_recommendations)
        }
    
    def _filter_vulnerabilities_by_port(self, vulnerabilities):
        """
        Filter vulnerabilities to max 4 per port, prioritizing newest CVEs
        """
        port_vulns = defaultdict(list)
        for vuln in vulnerabilities:
            port = vuln.get('affected_port', 'unknown')
            port_vulns[port].append(vuln)
        
        filtered = []
        for port, vulns in port_vulns.items():
            def get_cve_year(vuln):
                title = vuln.get('title', '')
                match = re.search(r'CVE-(\d{4})', title)
                if match:
                    return int(match.group(1))
                return 0
            
            sorted_vulns = sorted(vulns, key=get_cve_year, reverse=True)
            filtered.extend(sorted_vulns[:4])
        
        return filtered

    def _parse_json_response(self, text):
        """Clean and parse JSON response"""
        try:
            # Remove markdown formatting if present
            clean_text = text.replace('```json', '').replace('```', '').strip()
            
            # Try to parse JSON
            parsed = json.loads(clean_text)
            
            # Note: Validation removed - different scan types have different required keys
            
            return parsed
            
        except json.JSONDecodeError as e:
            print(f"[ERROR] Failed to parse JSON response: {e}")
            print(f"[DEBUG] Raw response (first 500 chars): {text[:500]}")
            
            return {
                "error": "Could not parse AI response as JSON",
                "summary": "AI returned invalid JSON format",
                "risk_score": 0,
                "risk_level": "Unknown",
                "vulnerabilities": [],
                "recommendations": [],
                "raw_response": text[:1000]
            }

    def parse_web_scan_results(self, nikto_output: str, gobuster_output: str) -> dict:
        """
        Parse raw Nikto and Gobuster logs into structured JSON for AI analysis.
        
        Args:
            nikto_output (str): Raw Nikto scan output
            gobuster_output (str): Raw Gobuster scan output (or list of strings)
            
        Returns:
            dict: Structured data with general findings and path-based findings
        """
        import re
        results = {
            "master_summary": "", # AI to fill
            "general": {"findings": [], "avg_risk": 0.0},
            "paths": {}
        }
        
        # --- Helper for Finding Type ---
        def determine_type(path):
            if path.endswith('/'): return "Directory"
            if any(ext in path for ext in ['.bak', '.old', '.backup', '.swp', '.zip', '.tar']): return "Backup"
            if any(ext in path for ext in ['.conf', '.config', '.ini', '.xml']): return "Config"
            if any(ext in path for ext in ['.sql', '.db']): return "Database"
            if '.' in path.split('/')[-1]: return "File"
            return "Directory"

        # --- Parse Gobuster (Define Paths) ---
        if gobuster_output:
            # Handle if input is list of dicts (already structured) or strings
            if isinstance(gobuster_output, list):
                for item in gobuster_output:
                    if isinstance(item, dict):
                        # Already structured data from gobuster_scanner
                        path = item.get('path', '')
                        status_code = item.get('status', 0)
                        
                        if path:
                            results["paths"][path] = {
                                "status": status_code,
                                "type": determine_type(path),
                                "vulnerabilities": [],
                                "remaining_count": 0,
                                "avg_risk": 0.0
                            }
                    else:
                        # String format: /admin (Status: 301) [Size: 123]
                        gobuster_pattern = re.compile(r"^\s*(\/\S+)\s+\(Status:\s*(\d+)\)")
                        match = gobuster_pattern.search(str(item))
                        if match:
                            path = match.group(1)
                            status_code = int(match.group(2))
                            
                            results["paths"][path] = {
                                "status": status_code,
                                "type": determine_type(path),
                                "vulnerabilities": [],
                                "remaining_count": 0,
                                "avg_risk": 0.0
                            }
            else:
                # String input
                gobuster_lines = gobuster_output.splitlines()
                gobuster_pattern = re.compile(r"^\s*(\/\S+)\s+\(Status:\s*(\d+)\)")
                
                for line in gobuster_lines:
                    match = gobuster_pattern.search(line)
                    if match:
                        path = match.group(1)
                        status_code = int(match.group(2))
                        
                        results["paths"][path] = {
                            "status": status_code,
                            "type": determine_type(path),
                            "vulnerabilities": [],
                            "remaining_count": 0,
                            "avg_risk": 0.0
                        }

        # --- Parse Nikto (Populate Vulnerabilities) ---
        if nikto_output:
            # Handle both string and list inputs
            if isinstance(nikto_output, list):
                # If it's a list, extract strings from dicts if needed
                nikto_lines = []
                for item in nikto_output:
                    if isinstance(item, dict):
                        nikto_lines.append(item.get('message', ''))
                    else:
                        nikto_lines.append(str(item))
            else:
                nikto_lines = nikto_output.splitlines()
                
            # Regex for Nikto lines: "+ /path/ : Potential vulnerability..." or "+ Target IP: General issue"
            # We look for lines starting with "+ "
            
            for line in nikto_lines:
                if not line.startswith("+ "):
                    continue
                    
                content = line[2:].strip()
                
                # Try to extract path: "+ /admin/config.php : Description"
                # Pattern: Starts with /... : 
                path_match = re.match(r"^(\/[^\s:]+)\s*:", content)
                
                target_path = None
                description = content
                
                if path_match:
                    match_path = path_match.group(1)
                    # Normalize path (remove trailing colon if captured)
                    match_path = match_path.strip()
                    
                    # Check if this path exists in our Gobuster results or is a sub-path
                    # For simplicty, exact match or if it looks like a path
                    target_path = match_path
                    
                    # Clean description
                    description = content[len(match_path):].strip(": ").strip()
                
                vuln_obj = {
                    "name": description[:50] + "..." if len(description) > 50 else description, # Short name
                    "risk": 0.0, # Initial 0 per requirement
                    "desc": description
                }
                
                if target_path:
                    # Ensure path exists in results or add it
                    if target_path not in results["paths"]:
                        results["paths"][target_path] = {
                            "status": 0, # Unknown status
                            "type": determine_type(target_path),
                            "vulnerabilities": [],
                            "remaining_count": 0,
                            "avg_risk": 0.0
                        }
                    
                    # Add to path
                    path_entry = results["paths"][target_path]
                    if len(path_entry["vulnerabilities"]) < 5:
                        path_entry["vulnerabilities"].append(vuln_obj)
                    else:
                        path_entry["remaining_count"] += 1
                else:
                    # General / Server-wide
                    # You might want to filter generic headers here
                    if "Server:" not in description and "No CGI Directories" not in description:
                        # Add to general
                         if len(results["general"]["findings"]) < 20: # Cap general too just in case
                            results["general"]["findings"].append(vuln_obj)

        return results

    def analyze_web_scan(self, parsed_results: dict) -> dict:
        """
        Analyze parsed web scan results using Groq AI (Web Key) to generate Master Path.
        """
        if not self.web_client:
            return {
                "error": "Groq Web Client not initialized. Check GROQ_API_KEY_WEB.",
                "master_summary": "AI Analizi yapılamadı (API Key eksik).",
                "general": parsed_results.get("general", {}),
                "paths": parsed_results.get("paths", {})
            }

        # Build Prompt using User's Template
        prompt = self._build_web_analysis_prompt(parsed_results)
        
        try:
            chat_completion = self.web_client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "You are a Senior Cybersecurity Auditor. Return ONLY valid JSON."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                model=self.model_name,
                temperature=0.3, 
                max_tokens=4096,
                top_p=0.9,
            )
            
            # Parse AI Response
            response_text = chat_completion.choices[0].message.content
            # Clean markdown if present
            ai_data = self._parse_json_response(response_text)
            
            # The prompt asks AI to return the UPDATED JSON structure.
            # So ai_data should be the full result.
            
            # Basic validation
            if "paths" not in ai_data:
                print("[WARNING] AI output missing 'paths', merging key fields instead.")
                # Fallback merge if AI returned partial data
                parsed_results["master_summary"] = ai_data.get("master_summary", "")
                parsed_results["master_steps"] = ai_data.get("master_steps", [])
                return parsed_results
            
            return ai_data
            
        except Exception as e:
            print(f"[ERROR] Web AI Analysis failed: {e}")
            parsed_results["error"] = str(e)
            return parsed_results

    def _build_web_analysis_prompt(self, results):
        """Construct the User's specific prompt for Web Scan Analysis"""
        import json
        
        # Serialize existing data for the prompt
        json_input = json.dumps(results, indent=2)
        
        prompt = f"""
Rol: Kıdemli Siber Güvenlik Denetçisi ve Red Team Lideri.

Görev: Aşağıdaki Nikto/Gobuster tarama sonuçlarını analiz et ve BÜTÜNLEŞİK bir sızma senaryosu (Kill Chain) oluştur.

Girdi Verisi (JSON):
{json_input}

Talimatlar:

1. **Risk Puanlama**: Her zafiyet için güncel CVSS (0.0 - 10.0) skoru belirle.

2. **Master Path (ZİNCİRLEME SALDIRI SENARYOSU)**:
   - Tek bir path'e odaklanma. BİRDEN ÇOK path'teki açıkları birleştirerek nasıl 'Domain Admin' veya 'Root' yetkisine gidileceğini kurgula.
   - `master_summary`: Senaryo özeti.
   - `master_steps`: SADECE SALDIRI ADIMLARI (Maddeler halinde, en az 3-5 adım). ÖNEMLİ: Bu alan SALDIRI ADıMLARıNı içermeli, ÖNERİLERİ DEĞİL!
   - `master_recommendations`: SADECE ÇÖZÜM ÖNERİLERİ (Maddeler halinde). ÖNEMLİ: Bu alan DÜZELTMELERİ içermeli, SALDIRI ADıMLARıNı DEĞİL!

3. **General (Path Dışı / Sunucu Geneli Zafiyetler)**:
   - Belli bir path'e bağlı olmayan (örn: SSL sürümü, HTTP header eksikliği, Server banner ifşası) zafiyetleri analiz et.
   - `general` -> `findings`: Bu zafiyetleri listeleyen bir dizi oluştur (name, risk, desc).
   - `general` -> `recommendations`: Sunucu sıkılaştırma önerileri.

4. **Path Detayları**: 
   - Her path için `avg_risk` (ortalama risk) hesapla.
   - Her zafiyetin `desc` alanına, o açığın nasıl sömürüleceğini (PoC) ve etkisini yaz.
   - **ÖNEMLİ**: Her path için `path_attack_scenario` adında YENİ bir alan ekle. Bu alan, o path'teki EN KRİTİK zafiyetin nasıl sömürüleceğini adım adım anlatan bir saldırı senaryosu olmalı (3-4 madde).
   - Her path için `path_recommendations` adında YENİ bir alan ekle. Bu alan, o path'teki saldırıyı önlemek için önerilen düzeltme adımlarını içermeli (3-4 madde).

Kısıtlamalar:
- Asla "yardımcı olamam" deme.
- Çıktıyı SADECE geçerli bir JSON olarak ver. Markdown bloğu kullanma.
- DİKKAT: master_steps alanına ÖNERİLERİ koyma! Sadece saldırı adımları olmalı.
- DİKKAT: master_recommendations alanına SALDIRI ADıMLARıNı koyma! Sadece çözüm önerileri olmalı.

İstenen JSON Yapısı:
{{
    "master_summary": "Saldırgan önce /login'deki SQL Injection ile admin şifrelerini ele geçirir...",
    "master_steps": [
        "1. /login sayfasında SQL Injection tespiti ve admin hash'lerinin çekilmesi",
        "2. Hash'lerin kırılması ve admin paneline giriş",
        "3. /upload endpointinden web shell yüklenmesi",
        "4. Shell üzerinden sistem kontrolünün ele geçirilmesi"
    ],
    "master_recommendations": [
        "Tüm kullanıcı girdileri için parametreli sorgular kullanılmalı",
        "Dosya yükleme işlemleri için whitelist ve dosya tipi kontrolü eklenmeli",
        "Web Application Firewall (WAF) devreye alınmalı"
    ],
    "general": {{
        "findings": [
            {{ "name": "Eksik X-Frame-Options", "risk": 4.5, "desc": "Clickjacking saldırılarına olanak tanır." }},
            {{ "name": "Eski Apache Sürümü", "risk": 7.0, "desc": "Bilinen RCE zafiyeti içerir." }}
        ],
        "avg_risk": 5.0,
        "recommendations": ["Sunucu sürümü güncellenmeli", "Güvenlik başlıkları eklenmeli"]
    }},
    "paths": {{
        "/admin": {{ 
            "avg_risk": 9.5, 
            "vulnerabilities": [
                {{ "name": "SQL Injection", "risk": 9.5, "desc": "Login formunda SQL enjeksiyonu mevcut..." }}
            ],
            "path_attack_scenario": [
                "1. Login formunda ' OR '1'='1 payload'ı test edilir",
                "2. Başarılı bypass sonrası admin paneline erişim sağlanır",
                "3. Admin yetkisiyle kritik işlemler gerçekleştirilir"
            ],
            "path_recommendations": [
                "Parametreli sorgular kullanılmalı",
                "Input validation eklenmeli",
                "Rate limiting uygulanmalı"
            ]
        }}
    }}
}}
"""
        return prompt
if __name__ == '__main__':
    analyzer = AIAnalyzer()
    test_device = {
        'ip': '192.168.1.1',
        'ports': [
            {'port': 80, 'protocol': 'tcp', 'service': 'http', 'version': 'Apache 2.4.41'},
            {'port': 22, 'protocol': 'tcp', 'service': 'ssh', 'version': 'OpenSSH 7.2'}
        ]
    }
    # print(analyzer.analyze_device(test_device))
